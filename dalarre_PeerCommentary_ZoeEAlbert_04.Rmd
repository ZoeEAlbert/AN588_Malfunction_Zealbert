---
title: "peercommentary"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
summary(cars)
```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.

---
title: "AN588_Malfunction_Zealbert"
author: "Zoe Albert"
date: "10/20/2021"
output: html_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## R Markdown
```
## Including Plots
You can also embed plots, for example:
```{r pressure, echo=FALSE}
plot(pressure)
```
Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
----------------------------------------------------
###[1] Write a simple R function, Z.prop.test(), that can perform one- or two-sample Z-tests for proportion data, using the following guidelines:
Your function should take the following arguments: p1 and n1 (no default) representing the estimated proportion and sample size (i.e., based on your sample data); p2 and n2 (both defaulting to NULL) that contain a second sample’s proportion and sample size data in the event of a two-sample test; p0 (no default) as the expected value for the population proportion; and alternative (default “two.sided”) and conf.level (default 0.95), to be used in the same way as in the function t.test().
When conducting a two-sample test, it should be p1 that is tested as being smaller or larger than p2 when alternative=“less” or alternative=“greater”, the same as in the use of x and y in the function t.test().
The function should perform a one-sample Z-test using p1, n1, and p0 if either p2 or n2 (or both) is NULL.
The function should contain a check for the rules of thumb we have talked about (n∗p>5 and n∗(1−p)>5) to ensure the validity of assuming the normal distribution in both the one- and two-sample settings. If this is violated, the function should still complete but it should also print an appropriate warning message.
The function should return a list containing the members Z (the test statistic), P (the appropriate p value), and CI (the two-sided CI with respect to “conf.level” around p1 in the case of a one-sample test and around p2-p1 in the case of a two-sample test). For all test alternatives (“two.sided”, “greater”, “less”), calculate symmetric CIs based on quantiles of the normal distribution rather than worrying about calculating single-limit confidence bounds.

```{r: z.prop.test}
###First Sample
z.prop.test <- function(p1,n1,p0,p2=NULL,n2=NULL,conf.level=0.95,alternative="two.sided") {
   if(p1 == 0){
    return(0)}
    else {if((n1 * p1 < 5) | (n1 * (1-p1) > 5)){
          return(c("Warning: Not Normal", (p1-p0) / sqrt((p0 * (1-p0))/n1)))}
          else(return((p1-p0) / sqrt((p0 * (1-p0))/n1)))}
}
###Just plugging in what the instructions said.  Unsure if all right, especially second half.  This should be for one sample, following these rules of thumb. 
###two sample test
z.test.2 <- function(p1,n1,p0,p2,n2,conf.level=0.95,alternative="two.sided") {
   if(p1 == 0){
    return(0)}
    else {if((n1 * p1 < 5) | (n1 * (1-p1) > 5)){
          return(c("Warning: Not Normal", (p1-p0) / sqrt((p0 * (1-p0))/n1)))}
          else(return((p1-p0) / sqrt((p0 * (1-p0))/n1)))}
  ###for second sample
  if(p2 == 0){
    return(0)}
    else {if((n2 * p2 < 5) | (n2 * (1-p2) > 5)){
          return(c("Warning: Not Normal", (p2-p0) / sqrt((p0 * (1-p0))/n2)))}
          else(return((p2-p0) / sqrt((p0 * (1-p0))/n2)))}
}
###Note the similarity between the two
###Do I need to test each function?


## Diego: The rules you have to check are n∗p>5 and n∗(1−p)>5. You checked the first one correctly but for the second one you used > instead of <, which is what you need to use to discriminate the samples that don't follow the rule.
## Diego: You still have to write what happens in each alternative (the differences are in the p-value calculations)
## Diego: Also, your function only returns the Z statistic, but not the p-value and the CIs. You can make your function return more than one thing using c() or list().
## Diego: In the two sample test, you are not calculating the Z statistic of the difference of the proportions (p2-p1). Check the last part of Module 10, where it is explained how to calculate it.  
## Diego: although it's not complete, your function runs and calculates correctly the Z statistic in the 1 sample test, so good job! I didn't know the function "else" and I think it's very useful, so thank you for showing it to me!
```

```{r}
###one sample: sample proportion is 10%, size is 100, expected populaiton proportion is 25%. Is this anything???

z.prop.test(p1=.10,n1=100,p0=.25,p2=NULL,n2=NULL,conf.level=0.95,alternative="two.sided")

###two sample test: 
z.test.2(p1=.10,n1=100,p0=.25,p2=.15,n2=50,conf.level=0.95,alternative="two.sided")
```
###The function should return a list containing the members Z (the test statistic), P (the appropriate p value), and CI (the two-sided CI with respect to “conf.level” around p1 in the case of a one-sample test and around p2-p1 in the case of a two-sample test). For all test alternatives (“two.sided”, “greater”, “less”), calculate symmetric CIs based on quantiles of the normal distribution rather than worrying about calculating single-limit confidence bounds.


###[2] The dataset from Kamilar and Cooper has in it a large number of variables related to life history and body size. For this exercise, the end aim is to fit a simple linear regression model to predict longevity (MaxLongevity_m) measured in months from species’ brain size (Brain_Size_Species_Mean) measured in grams. Do the following for both longevity~brain size and log(longevity)~log(brain size):
Fit the regression model and, using {ggplot2}, produce a scatterplot with the fitted line superimposed upon the data. Append the the fitted model equation to your plot (HINT: use the function geom_text()).
Identify and interpret the point estimate of the slope (β1), as well as the outcome of the test associated with the hypotheses H0: β1 = 0; HA: β1 ≠ 0. Also, find a 90 percent CI for the slope (β1) parameter.
Using your model, add lines for the 90 percent confidence and prediction interval bands on the plot and add a legend to differentiate between the lines.
Produce a point estimate and associated 90 percent PI for the longevity of a species whose brain weight is 800 gm. Do you trust the model to predict observations accurately for this value of the explanatory variable? Why or why not?
Looking at your two models, which do you think is better? Why?

###Download the data
```{r}
library(curl)
f <- curl("https://raw.githubusercontent.com/fuzzyatelin/fuzzyatelin.github.io/master/AN588_Fall21/KamilarAndCooperData.csv")
d <- read.csv(f, header = TRUE, sep = ",", stringsAsFactors = FALSE)
head(d)
names(d)
###Is this right as a means of loading?

## Diego: Perfect!
```
###For this exercise, the end aim is to fit a simple linear regression model to predict longevity (MaxLongevity_m) measured in months from species’ brain size (Brain_Size_Species_Mean) measured in grams. Do the following for both longevity~brain size and log(longevity)~log(brain size):

```{r:plot}
plot(data = d, MaxLongevity_m ~ Brain_Size_Species_Mean)
```
```{r:model}
model <- lm(data = d, MaxLongevity_m ~ Brain_Size_Species_Mean)
summary(model)
plot(model)
```
```{r:Data Transformation: logs}
d$logMaxLongevity_m <- log(d$MaxLongevity_m)
d$logBrain_Size_Species_Mean <- log(d$Brain_Size_Species_Mean)
plot(data = d, logMaxLongevity_m ~ logBrain_Size_Species_Mean)
model <- lm(data = d, logMaxLongevity_m ~ logBrain_Size_Species_Mean)
summary(model)
plot(model)
```
###Identify and interpret the point estimate of the slope (β1), as well as the outcome of the test associated with the hypotheses H0: β1 = 0; HA: β1 ≠ 0. 
###Run a line in order to find the slope.

```{r}
library(ggplot2)
g <- ggplot(data = d, aes(x = d$logBrain_Size_Species_Mean, y = d$logMaxLongevity_m)) + geom_point()
g
```
```{r}
b <- d$logBrain_Size_Species_Mean
l <- d$logMaxLongevity_m
beta1 <- cor(b,l)/var(b)
beta1
##Diego: this returns N/A I don't know why

```
```{r}
m <- lm(l ~ b)
m
``` 
```{r: CI}
library(lmodel2)  
###load the lmodel2 package
mII <- lmodel2(MaxLongevity_m ~ Brain_Size_Species_Mean, data = d, range.y = "relative", range.x = "relative", 
    nperm = 1000)
mII
```
```{r}
plot(mII, "OLS") 
###plotting resuts of lmodel2
plot(mII, "RMA")
plot(mII, "SMA")
```
```{r:Plot CI and PI}
m <- lm(data = d, logMaxLongevity_m ~ logBrain_Size_Species_Mean)
h_hat <- predict(m, newdata = data.frame(logBrain_Size_Species_Mean = d$logBrain_Size_Species_Mean))
df <- data.frame(cbind(d$logBrain_Size_Species_Mean, d$logMaxLongevity_m, h_hat))
names(df) <- c("x", "y", "yhat")
head(df)
```
```{r}
ci <- predict(m, newdata = data.frame(logBrain_Size_Species_Mean = d$logBrain_Size_Species_Mean), interval = "confidence", 
    level = 0.90)  # for a vector of values
head(ci)
```
```{r:Plot Data Frame}
df <- cbind(df, ci)
names(df) <- c("x", "y", "yhat", "CIfit", "CIlwr", "CIupr")
head(df)
```
```{r:Upper and Lower Confidence Intervals}
g <- ggplot(data = df, aes(x = x, y = y))
g <- g + geom_point(alpha = 1/2)
g <- g + geom_line(aes(x = x, y = CIfit), colour = "black")
g <- g + geom_line(aes(x = x, y = CIlwr), colour = "blue")
g <- g + geom_line(aes(x = x, y = CIupr), colour = "blue")
g
```
```{r: PI and Data frame}
pi <- predict(m, newdata = data.frame(logBrain_Size_Species_Mean = d$logBrain_Size_Species_Mean), interval = "prediction", 
    level = 0.90)  
###for a vector of values
head(pi)
df <- cbind(df, pi) 
###dataframe
names(df) <- c("x", "y", "yhat", "CIfit", "CIlwr", "CIupr", "PIfit", "PIlwr", 
    "PIupr")
head(df)
```
```{r:All together}
g <- g + geom_line(data = df, aes(x = x, y = PIlwr), colour = "red")
g <- g + geom_line(data = df, aes(x = x, y = PIupr), colour = "red")
g


## Diego: Good job! I'm impressed! I didn't know the package lmodel2 and it is useful. I think everything is fine! (I just missed some more comments because sometimes it was hard for me to figure out what was each part of the code doing, but it's allright)
```
###Produce a point estimate and associated 90 percent PI for the longevity of a species whose brain weight is 800 gm. 




```{r}
pi <- predict(m, newdata = data.frame(logBrain_Size_Species_Mean = 800), interval = "prediction", 
    level = 0.9)
pi

## Diego: If you use the logarithm model, I think you have to introduce log(800) as logBrain_Size_Species_Mean, because 800 is the raw value in grams. But the code is perfect.
```
###estimate: 192.1986 for lower and upper: 168.6955, 215.7017

###Do you trust the model to predict observations accurately for this value of the explanatory variable? Why or why not?  No?  Because lots outside CI??? 
Diego: I think you can't trust it too much because we don't have points in the range of values we are predicting so we are not interpolating, we are extrapolating. Besides, the R-squared isn't to high and the PIs show that the value can fall in a range of 200 units.

Looking at your two models, which do you think is better? Why? Come back to this...
Diego: I think the logarithm model is better because the R-squared is higher and the PIs are tighter

1. The length of these modules is my biggest challenge.  I am the worlds slowest coder oh my goodness. 
2. I found some helpful things online, but now I don't think I did a great job annotating, becuase I am not positive what all I was doing. 
3. I am not sure about the sample numbers I chose in number 1. 
4. In general, I just need to go back over the modules again. 
5. Is Z.prop.test the same as Z.test?
6. I can't get the running thing to show up????
Diego: I don't know why, but I also couldn't get the running thing to show up in your code. I had to run each thing separately. Weird :/
