---
title: "Zealbert_FinalHomeworkCode_04"
author: "Zoe Albert"
date: "10/28/2021"
output: html_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## R Markdown
```
## Including Plots
You can also embed plots, for example:
```{r pressure, echo=FALSE}
plot(pressure)
```
Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
----------------------------------------------------
###[1] Write a simple R function, Z.prop.test(), that can perform one- or two-sample Z-tests for proportion data, using the following guidelines:
Your function should take the following arguments: p1 and n1 (no default) representing the estimated proportion and sample size (i.e., based on your sample data); p2 and n2 (both defaulting to NULL) that contain a second sample’s proportion and sample size data in the event of a two-sample test; p0 (no default) as the expected value for the population proportion; and alternative (default “two.sided”) and conf.level (default 0.95), to be used in the same way as in the function t.test().
When conducting a two-sample test, it should be p1 that is tested as being smaller or larger than p2 when alternative=“less” or alternative=“greater”, the same as in the use of x and y in the function t.test().
The function should perform a one-sample Z-test using p1, n1, and p0 if either p2 or n2 (or both) is NULL.
The function should contain a check for the rules of thumb we have talked about (n∗p>5 and n∗(1−p)>5) to ensure the validity of assuming the normal distribution in both the one- and two-sample settings. If this is violated, the function should still complete but it should also print an appropriate warning message.
The function should return a list containing the members Z (the test statistic), P (the appropriate p value), and CI (the two-sided CI with respect to “conf.level” around p1 in the case of a one-sample test and around p2-p1 in the case of a two-sample test). For all test alternatives (“two.sided”, “greater”, “less”), calculate symmetric CIs based on quantiles of the normal distribution rather than worrying about calculating single-limit confidence bounds.

```
```{r}
z.prop.test <-function(p1,n1,p0,p2=NULL,n2=NULL,conf.level=0.95,alternative="two.sided") 
  {if(p1 == 0){return(0)}else {if((n1 * p1 < 5) | (n1 * (1-p1) > 5)){return(c("Warning: Not Normal", (p1-p0) / sqrt((p0 * (1-p0))/n1)))} else(return((p1-p0) / sqrt((p0 * (1-p0))/n1)))}}
###I don't fully understand why and how you know to do different lines.  It seems like this doesn't matter. Spacing doesn't matter. 
###Only works with two ==
###Just plugging in what the instructions said.  Unsure if all right, especially second half.  This should be for one sample, following these rules of thumb. 
###two sample test
z.test.2 <- function(p1,n1,p0,p2,n2,conf.level=0.95,alternative="two.sided") {if(p1 == 0){return(0)}
else {if((n1 * p1 < 5) | (n1 * (1-p1) < 5)){return(c("Warning: This aint normal", (p1-p0) / sqrt((p0 * (1-p0))/n1)))}
else(return((p1-p0) / sqrt((p0 * (1-p0))/n1)))}
  ###I realized I could have it give me funny warnings, so I added this.  Kind of makes coding more fun, no?
  ###for second sample
if(p2 == 0){return(0)}else {if((n2 * p2 < 5) | (n2 * (1-p2) < 5)){return(c("Warning: A real not normal situation you got yourself here, buddy", (p2-p0) / sqrt((p0 * (1-p0))/n2)))}else(return((p2-p0) / sqrt((p0 * (1-p0))/n2)))}}
###Note the similarity between the two
###Do I need to test each function?
###I really struggling with reading all of the instructions and knowing what order I should do things in... I am also not sure what I missed if anything and why...
###I am not getting any errors when I run the chunk. 
###This function isn't working:   return(list(z,p,ci))  Maybe I am running it too early?
###This is a good way to add the label: 
     ###  cat( "Z_score =", Z.two.sample <- Z.two.sample, "\n", 
     ###"CI =", CI.two.sample <- CI.two.sample, "\n", 
     ###"P-Value =", P.Value <- P.Value, "\n") }
###IF YOU TYPE IN THE NAME OF A FUNCTION, WITH NO PARENTHESIS, AND PRESS ENTER, YOU CAN SEE WHAT IS "UNDER THE HOOD". 



###This is the information that I find for it online: prop.test(x, n, p = NULL, alternative = “two.sided”, correct = TRUE)
#########x: a vector of counts of successes
#########n: a vector of count trials
#########alternative: a character string specifying the alternative hypothesis
#########correct: a logical indicating whether Yates’ continuity correction should be applied where possible
#########Note that, by default, the function prop.test() used the Yates continuity correction, which is really important if either the expected successes or failures is < 5. If you don’t want the correction, use the additional argument correct = FALSE in prop.test() function. The default value is TRUE. (This option must be set to FALSE to make the test mathematically equivalent to the uncorrected z-test of a proportion.)
```

*you should be able to make one function defining all variables, for the one and two sample test (for one sample, you will set: if (is.null(p2) == TRUE || is.null(n2) == TRUE)) and your "else" will be when they are not null (i.e. you have p2 and n2 values) then define the upper and lower CI for when p2 and n2 are and are not null.*

```{r}
###one sample: sample proportion is 10%, size is 100, expected population proportion is 25%. Is this anything???
###two sample: proportion is 50% size is 500 expected is 30%

z.prop.test(p1=.10,n1=100,p0=.25,p2=NULL,n2=NULL,conf.level=0.95,alternative="two.sided")
z.prop.test(p1=.50,n1=500,p0=.30,p2=NULL,n2=NULL,conf.level=0.95,alternative="two.sided")

###two sample test: 
z.test.2(p1=.10,n1=100,p0=.25,p2=.15,n2=50,conf.level=0.95,alternative="two.sided")
z.test.2(p1=.50,n1=500,p0=.30,p2=.15,n2=50,conf.level=0.95,alternative="two.sided")
###What are P2 and n2??????
```
###The function should return a list containing the members Z (the test statistic), P (the appropriate p value), and CI (the two-sided CI with respect to “conf.level” around p1 in the case of a one-sample test and around p2-p1 in the case of a two-sample test). For all test alternatives (“two.sided”, “greater”, “less”), calculate symmetric CIs based on quantiles of the normal distribution rather than worrying about calculating single-limit confidence bounds.
```{r}
   z.prop.test(p1 = 0.6, n1 = 30, p0 = 0.5, conf.level = 0.95) 
    z.prop.test(p1 = 0.6, n1 = 5, p0 = 0.5, alternative = "less", conf.level = 0.95)
    z.prop.test(p1 = 0.6, n1 = 30, p0 = 0, p2 = 0.8, n2 = 25, conf.level = 0.95)
    z.prop.test(p1 = 0.6, n1 = 30, p0 = 0.4, n2 = 25, conf.level = 0.95)
    z.prop.test(p1 = 0.6, n1 = 50, p0 = 0, p2 = 0.8, n2 = 60, alternative = "greater", conf.level = 0.95)
    ###Was hoping my silly not normal error would show up.  Oh well!  
    ###MANY MANY MANY THANKS to Diego for helping me with this part. 
    ### What does "Inf" mean in the answer??????? I get this for the 3rd and 5th rows. 
```
###[2] The dataset from Kamilar and Cooper has in it a large number of variables related to life history and body size. For this exercise, the end aim is to fit a simple linear regression model to predict longevity (MaxLongevity_m) measured in months from species’ brain size (Brain_Size_Species_Mean) measured in grams. Do the following for both longevity~brain size and log(longevity)~log(brain size):
Fit the regression model and, using {ggplot2}, produce a scatterplot with the fitted line superimposed upon the data. Append the the fitted model equation to your plot (HINT: use the function geom_text()).
Identify and interpret the point estimate of the slope (β1), as well as the outcome of the test associated with the hypotheses H0: β1 = 0; HA: β1 ≠ 0. Also, find a 90 percent CI for the slope (β1) parameter.
Using your model, add lines for the 90 percent confidence and prediction interval bands on the plot and add a legend to differentiate between the lines.
Produce a point estimate and associated 90 percent PI for the longevity of a species whose brain weight is 800 gm. Do you trust the model to predict observations accurately for this value of the explanatory variable? Why or why not?
Looking at your two models, which do you think is better? Why?

###Download the data
```{r} 
library(curl)
f <- curl("https://raw.githubusercontent.com/fuzzyatelin/fuzzyatelin.github.io/master/AN588_Fall21/KamilarAndCooperData.csv")
d <- read.csv(f, header = TRUE, sep = ",", stringsAsFactors = FALSE)
head(d)
names(d)
###Is this right as a means of loading?  I think I feel pretty confident about this one. 
```
###For this exercise, the end aim is to fit a simple linear regression model to predict longevity (MaxLongevity_m) measured in months from species’ brain size (Brain_Size_Species_Mean) measured in grams. Do the following for both longevity~brain size and log(longevity)~log(brain size):

```{r}
plot(data = d, MaxLongevity_m ~ Brain_Size_Species_Mean)
###What even is this graph.  A whole hodgepodge is what it is. 
```
```{r}
model <- lm(data = d, MaxLongevity_m ~ Brain_Size_Species_Mean)
summary(model)
plot(model)
```
```{r}
d$logMaxLongevity_m <- log(d$MaxLongevity_m)
d$logBrain_Size_Species_Mean <- log(d$Brain_Size_Species_Mean)
plot(data = d, logMaxLongevity_m ~ logBrain_Size_Species_Mean)
model <- lm(data = d, logMaxLongevity_m ~ logBrain_Size_Species_Mean)
summary(model)
plot(model)
###I can just click through to see all the graphs. 
```
###Identify and interpret the point estimate of the slope (β1), as well as the outcome of the test associated with the hypotheses H0: β1 = 0; HA: β1 ≠ 0. 
###Run a line in order to find the slope.

```{r}
library(ggplot2)
g <- ggplot(data = d, aes(x = d$logBrain_Size_Species_Mean, y = d$logMaxLongevity_m)) + geom_point()
g
###Kind of positive correlation. 
```

*Don't forget to add a line with geom_smooth(). also plot your not-logged data for comparison (also with ggplot). You can add the equation using annotated("text", label = "your equation") with the equation being based off of the interpretted coefficients given in your modle summary.*

```{r}
b <- d$logBrain_Size_Species_Mean
l <- d$logMaxLongevity_m
m <- lm(l ~ b)
m
###Coefficients:Intercept = 4.8790 and b = 0.2341

```

*Intercept is the y intercept, b is the slope, B0 and B1 respectively.*

```{r}

library(lmodel2)  
###load the lmodel2 package
mII <- lmodel2(MaxLongevity_m ~ Brain_Size_Species_Mean, data = d, range.y = "relative", range.x = "relative", 
    nperm = 1000)
mII

```

```{r}

plot(mII, "OLS") 
###OLS stands for ordinary least squares
###plotting results of lmodel2
plot(mII, "RMA")
###RMA stands for Robust multi-aray average
plot(mII, "SMA")
###SMA is simple moving average 
###Shows a positive trend, but looks like a hodge podge to me still. 
```

```{r}
m <- lm(data = d, logMaxLongevity_m ~ logBrain_Size_Species_Mean)
h_hat <- predict(m, newdata = data.frame(logBrain_Size_Species_Mean = d$logBrain_Size_Species_Mean))
df <- data.frame(cbind(d$logBrain_Size_Species_Mean, d$logMaxLongevity_m, h_hat))
names(df) <- c("x", "y", "yhat")
head(df)
```

*missing the interval in your predict function*

```{r} 
ci <- predict(m, newdata = data.frame(logBrain_Size_Species_Mean = d$logBrain_Size_Species_Mean), interval = "confidence", 
    level = 0.90)  # for a vector of values
head(ci)
```

```{r}
df <- cbind(df, ci)
names(df) <- c("x", "y", "yhat", "CIfit", "CIlower", "CIupper")
###Naming the columns
head(df)
```

```{r}
###Upper and Lower Confidence Intervals 
###SHOOT. I can't remember how to call ggplot....curl?install?library?
###Does anyone else feel like a G-D when they finally figure out the most basic thing in R?!?!?!
library(ggplot2)
g <- ggplot(data = df, aes(x = x, y = y))
g <- g + geom_point(alpha = 1/2)
g <- g + geom_line(aes(x = x, y = CIfit), colour = "red")
g <- g + geom_line(aes(x = x, y = CIlower), colour = "blue")
g <- g + geom_line(aes(x = x, y = CIupper), colour = "green")
g
###Okay, I can kind of see the trend.  I get what I did so that's neat. 
```

*You want the original best fit line from your original plot, and PI and CI [one color for CI one for PI]*

#####WarrenKevins Code:
model1 <- lm(KC$MaxLongevity_m ~ KC$Brain_Size_Species_Mean)
summary(model1)
x <- KC$Brain_Size_Species_Mean
y <- KC$MaxLongevity_
conf_interval <- predict(model1, newdata = data.frame(Brain_Size_Species_Mean = x),, interval = "confidence", level = 0.90)
colnames(conf_interval) <-c("Fit_C","Lower_C","Upper_C")
head(conf_interval)
summary(KC$MaxLongevity_m)
pred_interval <- predict(model1, newdata = data.frame(Brain_Size_Species_Mean = x),, interval = "prediction", level = 0.90)
colnames(pred_interval) <-c("Fit_P","Lower_P","Upper_P")
ggplot(mydata, aes(x = x, y = y)) + theme_minimal() +
          geom_point() + labs(x = "log(Mean Species Brain Size)", y = "log(Max Longevity)", size = 14) +
          geom_line(aes(x = x, y = Fit_C, color = "Confidence")) +
          geom_line(aes(x = x, y = Lower_C, color = "Confidence")) +
          geom_line(aes(x = x, y = Upper_C, color = "Confidence")) + geom_smooth(method=lm)

```{r}
###PI and Data frame
pi <- predict(m, newdata = data.frame(logBrain_Size_Species_Mean = d$logBrain_Size_Species_Mean), interval = "prediction", level = 0.90)  
###introduce log(800) as logBrain_Size_Species_Mean????
###for a vector of values
head(pi)
df <- cbind(df, pi) 
###dataframe
names(df) <- c("x", "y", "yhat", "CIfit", "CIlower", "CIupper", "PIfit", "PIlower","PIupper")
###Those bad boys need a name. 
###I wish there was a way to make the uppercase I look like less of an lowercase l in the table. 
head(df)
```

```{r}
###All together
g <- g + geom_line(data = df, aes(x = x, y = PIlower), colour = "red")
g1 <- g + geom_line(data = df, aes(x = x, y = PIupper), colour = "darkgreen")
g
###I changed the name and now its kinda screwed up and I am not sure why...It also doesn't give me an error until I call the specific function, which feels problematic I won't lie...I fixed it because I am a genius.  Moral of the story, don't change names halfway thorough. 
```
###Produce a point estimate and associated 90 percent PI for the longevity of a species whose brain weight is 800 gm. 

```{r} 
pi <- predict(m, newdata = data.frame(logBrain_Size_Species_Mean = 800), interval = "prediction", 
    level = 0.9)
pi
```
###estimate: 192.1986 for lower and upper: 168.6955, 215.7017

###Do you trust the model to predict observations accurately for this value of the explanatory variable? Why or why not?  No?  Because lots outside CI???--> We can't trust this very much because our value are not in the range we predicted. 

Looking at your two models, which do you think is better? Why?  Thanks to help from Diego, I think the logarithm model is better than the other model.  This is because the R squared is higher and the PIs are tighter. 

1. The length of these modules is my biggest challenge.  I am the worlds slowest coder oh my goodness. 
2. I found some helpful things online, but now I don't think I did a great job annotating, because I am not positive what all I was doing. 
3. I am not sure about the sample numbers I chose in number 1. 
4. In general, I just need to go back over the modules again. 
5. Is Z.prop.test the same as Z.test?
6. I can't get the running thing to show up????

###Someone had told me on an earlier assignment that I could put descritions in the {r} on the top of my code, but when I do that it doesnt run anymore...
###I feel like I am relying really heavily on other peoples codes and help material that I find online. 

*I know this assignment was a doozy. As far as the regression part goes, try to think about when you want to log transform the data (has to do with the distribution) and the interpretation of your beta values (think about your basic y=mx+b equation). Practicing ggplot will help you because then you can constantly check what your regression looks like. As far as ggplot goes, looking on the internet and other people's code is honestly a great way to learn!*